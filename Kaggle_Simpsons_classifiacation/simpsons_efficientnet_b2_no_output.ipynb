{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQlDjKcWcb1I"
   },
   "source": [
    "\n",
    "\n",
    "## **Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw7YkEefehWo"
   },
   "source": [
    "# Путешествие по Спрингфилду.\n",
    "\n",
    "\n",
    "Сегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.\n",
    "\n",
    "\n",
    "\n",
    " ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG47vhLxKNln"
   },
   "source": [
    "### Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4PIHZXbXjSf"
   },
   "outputs": [],
   "source": [
    "# ignore deprication warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# standard python modules\n",
    "import os, sys\n",
    "import time\n",
    "\n",
    "\n",
    "# standard ml modules\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt, colors\n",
    "# work in interactive mode\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# loading files (in parallel)\n",
    "from pathlib import Path\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "\n",
    "# working with images\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# interacrive timing\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "# saving models \n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQGdYoQfXjXs",
    "outputId": "d2a23685-9f2a-4f9e-8684-03a3ad96eb31"
   },
   "outputs": [],
   "source": [
    "print(PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VK6cDeNBXjVu",
    "outputId": "f0dc81e9-2452-4959-f446-666c1da27f67"
   },
   "outputs": [],
   "source": [
    "print(\"torch.__version__ :\", torch.__version__)\n",
    "print(\"torchvision.__version__ :\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLYJc088XuFi"
   },
   "source": [
    "### Выбираем GPU для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tooF65TcX4tE",
    "outputId": "a98793c0-7a18-4a60-a3a1-7a2d15ade992"
   },
   "outputs": [],
   "source": [
    "# we will verify that GPU is enabled for this notebook\n",
    "# following should print: CUDA is available!  Training on GPU ...\n",
    "# \n",
    "# if it prints otherwise, then you need to enable GPU: \n",
    "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JreL-k2uX4wD"
   },
   "outputs": [],
   "source": [
    "# different modes of dataset\n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# all images will be scaled to size 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# we work on a video card\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82zAqQdkX4ze",
    "outputId": "31a7f199-0eda-4266-aefd-8831ab99ae5e"
   },
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dNQWwgrYCeV"
   },
   "outputs": [],
   "source": [
    "# делаем результат воспроизводимым\n",
    "SEED = 111\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmfTdzeMYQn_"
   },
   "source": [
    "### Подготовка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD_8gK6PmgXk"
   },
   "source": [
    "В нашем тесте будет 990 картинок, для которых вам будет необходимо предсказать класс.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYFeKUzfy572"
   },
   "source": [
    "https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ecnkB2xK1aE"
   },
   "source": [
    "Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. \n",
    "\n",
    "ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n",
    "$input = \\frac{input - \\mu}{\\text{standard deviation}} $, <br>       константы - средние и дисперсии по каналам на основе ImageNet\n",
    "\n",
    "\n",
    "Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n",
    " Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsCVEQlgYgEg"
   },
   "source": [
    "### Class for loading the data from folders in parallel¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj32U5iTQUe4"
   },
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который \n",
    "    - параллельно подгружает их из папок\n",
    "    - производит скалирование \n",
    "    - превращение в PyTorch тензоры\n",
    "\n",
    "    Class to work with image dataset, which\n",
    "    - loads them form the folders in parallel\n",
    "    - converts to PyTorch tensors\n",
    "    - scales the tensors to have mean = 0, standard deviation = 1\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        self.files = sorted(files) # list of files to be loaded\n",
    "        self.mode = mode           # working mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "    \n",
    "    \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # converts to PyTorch tensors and normalises the input\n",
    "\n",
    "        # augumentation realised here \n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.RandomRotation(degrees=30),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ColorJitter(hue=.1, saturation=.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ]),\n",
    "            'val_test': transforms.Compose([\n",
    "                transforms.Resize(size=(RESCALE_SIZE, RESCALE_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                # у этих картинок mean и std задаются такими значениями\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        transform = (data_transforms['train'] if self.mode == 'train' else data_transforms['val_test'])\n",
    "        \n",
    "        x = self.load_sample(self.files[index])  # load image\n",
    "        x = transform(x)                         # apply transform defined above\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_odtTEzcaWH"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALjbTKh4Y2w6"
   },
   "source": [
    "### Считываем файлы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncD4zzUnZJcc",
    "outputId": "5f3437dd-8aa8-4010-821f-45defee33be3"
   },
   "outputs": [],
   "source": [
    "# подключаемся к Google Drive\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFJ-umErZJfd"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/gdrive/\\ MyDrive/Simpsons_kaggle/simpsons_dataset.zip -d train\n",
    "!unzip -q /content/gdrive/\\ MyDrive/Simpsons_kaggle/testset.zip -d test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUhzOq1zRJil"
   },
   "outputs": [],
   "source": [
    "# Путь до директории на Google Drive\n",
    "TRAIN_DIR = Path('train/simpsons_dataset')\n",
    "TEST_DIR = Path('test/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IuZ66vrXZWXi",
    "outputId": "0bbfd5dc-19cc-4a8b-e3b9-dbfaf9208f7a"
   },
   "outputs": [],
   "source": [
    "print(len(train_val_files), 'train files')\n",
    "train_val_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YcKKqWkZWaa",
    "outputId": "099af99b-8abe-44ab-97c3-d6e24012050d"
   },
   "outputs": [],
   "source": [
    "print(len(test_files), 'test files')\n",
    "test_files[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXIjtogoZWfa"
   },
   "outputs": [],
   "source": [
    "# path.parent.name returns a folder \n",
    "# in which the image is, which corresponds to the label in nthis case\n",
    "train_val_labels = [path.parent.name for path in train_val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xeF0Y9VZWdw",
    "outputId": "7b931d10-d894-4801-a7d8-c9ece8a872d0"
   },
   "outputs": [],
   "source": [
    "print(len(train_val_labels), 'train_val_labels')\n",
    "train_val_labels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtOrIEd0ZeGw"
   },
   "source": [
    "## Обучение\n",
    "\n",
    "\n",
    "### Разделение на train-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmPhhKKlRyCF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.20, stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k9Z4k7nx5aY"
   },
   "outputs": [],
   "source": [
    "N_CLASSES = len(np.unique(train_val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZHOTvDdydsx"
   },
   "outputs": [],
   "source": [
    "val_dataset = SimpsonsDataset(val_files, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQh18GhKx3nB"
   },
   "outputs": [],
   "source": [
    "if val_dataset is None:\n",
    "    val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "    \n",
    "train_dataset = SimpsonsDataset(train_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFaQJSX53UlK"
   },
   "source": [
    "Среди изображений есть персонажи, которые всречаются всего несколько раз в тренировочной выборке. Дополним число изображений с этими персонажами до 100 штук, аугументацию не используем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78nrNnOFxVqu",
    "outputId": "caec0526-ff0c-460e-f383-4896ec112d1f"
   },
   "outputs": [],
   "source": [
    "def create_dct_path_labels(train_files, train_labels):\n",
    "    dct_simpsons = {}\n",
    "    for label_i in np.unique(train_labels).tolist():\n",
    "        dct_simpsons[label_i] = []\n",
    "\n",
    "    for path_i, label_i in zip(train_files, train_labels):\n",
    "        dct_simpsons[label_i].append(path_i)\n",
    "\n",
    "    return dct_simpsons\n",
    "\n",
    "# Создадим словарь в котором ключами будут персонажи Симпсонов, а значениями списки с путями к картинкам.\n",
    "dct_path_train = create_dct_path_labels(train_files, train_dataset.labels)\n",
    "\n",
    "# Дополним картинки классов у которых менее 100 картинок, до 100 картинок в классе\n",
    "for person in dct_path_train:\n",
    "    if len(dct_path_train[person]) < 100:\n",
    "        dct_path_train[person] = dct_path_train[person] * (100 // len(dct_path_train[person]))\n",
    "        dct_path_train[person].extend(dct_path_train[person][:100 - len(dct_path_train[person])])\n",
    "# Проверим что получилось \n",
    "for person in dct_path_train:\n",
    "    print(f\"{person}\\t{len(dct_path_train[person])}\")\n",
    "new_train_files = []\n",
    "\n",
    "for person in dct_path_train:\n",
    "    new_train_files.extend(dct_path_train[person])\n",
    "\n",
    "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
    "train_dataset = SimpsonsDataset(new_train_files, mode='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmKSdyv1b7PD"
   },
   "source": [
    "Давайте посмотрим на наших героев внутри датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "ltitWp3lXAZt",
    "outputId": "a1078d58-fed3-4221-c31a-a716f9a6b95c"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6YcZk8vQR47"
   },
   "source": [
    "### Функции для тренировки сети\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2mk7MNtcUhJ"
   },
   "outputs": [],
   "source": [
    "def fit_epoch(model, train_loader, criterion, optimizer):\n",
    "    # initialize tracked variables\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_data = 0\n",
    "  \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        # reset the gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predictions (probabilities), loss, backprop\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # weights update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # predictions (classes)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        \n",
    "        # record tracked items\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_data += inputs.size(0)\n",
    "        \n",
    "    # record train loss and train accuracy          \n",
    "    train_loss = running_loss / processed_data\n",
    "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_CD9--hcUjs"
   },
   "outputs": [],
   "source": [
    "def eval_epoch(model, val_loader, criterion):\n",
    "    # set model model into the evaluation mode (e.g. for Dropout)\n",
    "    model.eval()\n",
    "    \n",
    "    # initialize tracked variables\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    processed_size = 0\n",
    "\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "        \n",
    "        # record tracked items\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        processed_size += inputs.size(0)\n",
    "        \n",
    "    # record val loss and val accuracy\n",
    "    val_loss = running_loss / processed_size\n",
    "    val_acc = running_corrects.double() / processed_size\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaxYIwB3cUmX"
   },
   "outputs": [],
   "source": [
    "def train(train_dataset, val_dataset, model, criterion,\n",
    "          epochs, batch_size, optimizer, scheduler,\n",
    "          shuffle=True, sampler=None, patience=5):\n",
    "    \n",
    "    # to record the total training time\n",
    "    since = time.time()\n",
    "    \n",
    "    # note: 4 workers loading the data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # init variables to store best model weights, best accuracy, best epoch number, epochs since best accuracy acheived\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10\n",
    "    best_epoch = 0\n",
    "    epochs_since_best = 0\n",
    "    \n",
    "    # history and log\n",
    "    history = []\n",
    "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
    "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
    "\n",
    "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            print(f\"epoch {epoch}:\\n\")\n",
    "            \n",
    "            print(\"Fitting on train data...\")\n",
    "            # all arguments except train loader are from parameters passed to train() arguments\n",
    "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, optimizer)\n",
    "            print(\"train loss:\", train_loss)\n",
    "            \n",
    "            print(\"Evaluating on validation data...\")\n",
    "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "            print(\"val loss:\", val_loss)\n",
    "            \n",
    "            # record history\n",
    "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
    "            \n",
    "            # update learning rate for the optimizer\n",
    "            scheduler.step()\n",
    "            \n",
    "            # display learning status\n",
    "            pbar_outer.update(1)\n",
    "            tqdm.write(log_template.format(ep=epoch, t_loss=train_loss,\\\n",
    "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            \n",
    "            # deep copy the model if it acheives the best validation performance\n",
    "            if val_loss < best_loss:\n",
    "                best_acc = val_loss\n",
    "                best_epoch = epoch\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print()\n",
    "            else:\n",
    "                epochs_since_best += 1\n",
    "            \n",
    "            # early stopping\n",
    "            if epochs_since_best > patience:\n",
    "                print(f'Stopping training. The validation metric has not improved for {patience} epochs.')\n",
    "                break\n",
    "            \n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    print('Best epoch: {}'.format(best_epoch))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v6G7qbYqcUpL"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "        \n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "            \n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo3UND5RdgVg"
   },
   "source": [
    "### Training only the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gmu4zcHxkQAB",
    "outputId": "ecb7663f-fe80-4195-d84c-58f149df4564"
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdPxJJGvkQDM"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FBXGxSrkTbG"
   },
   "outputs": [],
   "source": [
    "model_name = 'efficientnet-b2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "UDyc0tKTkTgv",
    "outputId": "6789db23-120c-4c82-e285-81eb1e24ed4e"
   },
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvS7p1IekTlz"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDmPTR85kTeW"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model._fc.in_features\n",
    "model._fc = nn.Linear(num_ftrs, N_CLASSES)\n",
    "\n",
    "# to GPU\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# learning rate optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "# scheduler for the lr optimizer\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4s14ZSdXkbA-"
   },
   "outputs": [],
   "source": [
    "model._fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL2vSQwnkbG9"
   },
   "outputs": [],
   "source": [
    "# feature_extr_epochs = 1 # test run\n",
    "feature_extr_epochs = 5 # performance run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYBR3Q78kbEJ"
   },
   "outputs": [],
   "source": [
    "history_feature_extr = train(train_dataset, val_dataset, model=model, criterion=criterion,\n",
    "                             epochs=feature_extr_epochs, batch_size=256, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qMAdL_BduXZ"
   },
   "source": [
    "Построим кривые обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ryD_9yFdfNr"
   },
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history_feature_extr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpQDWGkfdfQ5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(loss, label=\"train_loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PId0bFxknaO"
   },
   "source": [
    "## Training all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ya9iiobtkmrb"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_Y3cx-0kmw3"
   },
   "outputs": [],
   "source": [
    "# finetuning_epochs = 1 # test run\n",
    "finetuning_epochs = 15 # performance run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-3bScq3km0z"
   },
   "outputs": [],
   "source": [
    "history_fine_tune = train(train_dataset=train_dataset, val_dataset=val_dataset, model=model, criterion=criterion,\n",
    "                          epochs=finetuning_epochs, batch_size=64, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dm3a6OS6k2H8"
   },
   "source": [
    "Построим кривые обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZYXr837kmvI"
   },
   "outputs": [],
   "source": [
    "loss, acc, val_loss, val_acc = zip(*history_fine_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlK-rC0Tk4nv"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(loss, label=\"train_loss\")\n",
    "plt.plot(val_loss, label=\"val_loss\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "\n",
    "plt.savefig(f\"{model_name}_{feature_extr_epochs}FeatureExtrEpochs-{finetuning_epochs}FinetuningEpochs-LearningCurve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUXoBl-Mk4tN"
   },
   "outputs": [],
   "source": [
    "f\"{model_name}_{feature_extr_epochs}FeatureExtrEpochs-{finetuning_epochs}FinetuningEpochs-LearningCurve.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0w87rVLdk4rT"
   },
   "outputs": [],
   "source": [
    "# save the weights of our net\n",
    "model_weights = copy.deepcopy(model.state_dict())\n",
    "torch.save(model_weights, f\"{model_name}_{feature_extr_epochs}FeatureExtrEpochs-{finetuning_epochs}FinetuningEpochs-weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SqfHxLok_2L"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVOSikMrlCvO"
   },
   "outputs": [],
   "source": [
    "# загружаем сохраненное состояние весов нейросети\n",
    "model.load_state_dict(torch.load(f\"{model_name}_{feature_extr_epochs}FeatureExtrEpochs-{finetuning_epochs}FinetuningEpochs-weights.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gr9lRCJNNDfD"
   },
   "source": [
    "### Ну и что теперь со всем этим делать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSe0nQ-dJ8uy"
   },
   "source": [
    "![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5k0UGeTNaQX"
   },
   "source": [
    "Хорошо бы понять, как сделать сабмит. \n",
    "У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8PlF6o0N9O1"
   },
   "outputs": [],
   "source": [
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY_OoLoVO_9V"
   },
   "outputs": [],
   "source": [
    "random_characters = int(np.random.uniform(0,1000))\n",
    "ex_img, true_label = val_dataset[random_characters]\n",
    "probs_im = predict_one_sample(model, ex_img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caivVFeAN9SY"
   },
   "outputs": [],
   "source": [
    "idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
    "imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
    "\n",
    "probs_ims = predict(model, imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Zhkrtk0pgf5"
   },
   "source": [
    "### Compare actual and predicted class ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNMFc7sfQh1a"
   },
   "outputs": [],
   "source": [
    "actual_labels = [val_dataset[id][1] for id in idxs]\n",
    "actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZ40WeeRpnGH"
   },
   "outputs": [],
   "source": [
    "y_pred = np.argmax(probs_ims, -1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVePL0-BKHrF"
   },
   "source": [
    "Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_h-9dDWsKGU-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(actual_labels, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61pyPrl4p1gd"
   },
   "source": [
    "## Compare actual and predicted classes (strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfQe1WGSp43S"
   },
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ_jJMqvp4_d"
   },
   "outputs": [],
   "source": [
    "actual_class = [label_encoder.classes_[i] for i in actual_labels]\n",
    "actual_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovHbfZsDp48y"
   },
   "outputs": [],
   "source": [
    "preds_class = [label_encoder.classes_[i] for i in y_pred]\n",
    "preds_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aCO7q24p46y"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(actual_class, preds_class, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxB9pfPfdCHr"
   },
   "source": [
    "Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVjq4EC5ZZE7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    \n",
    "    \n",
    "\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)\n",
    "    \n",
    "    actual_text = \"Actual : {}\".format(img_label)\n",
    "            \n",
    "    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n",
    "    font0 = FontProperties()\n",
    "    font = font0.copy()\n",
    "    font.set_family(\"fantasy\")\n",
    "    prob_pred = predict_one_sample(model, im_val.unsqueeze(0))\n",
    "    predicted_proba = np.max(prob_pred)*100\n",
    "    y_pred = np.argmax(prob_pred)\n",
    "    \n",
    "    predicted_label = label_encoder.classes_[y_pred]\n",
    "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
    "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
    "            \n",
    "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
    "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hO9OLOMqIXRV"
   },
   "source": [
    "Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEWTL6jgdh7L"
   },
   "source": [
    "### Submit на Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrjQ6cxHIGtk"
   },
   "source": [
    "![alt text](https://i.redd.it/nuaphfioz0211.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UTbU0Zbc6Hb"
   },
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64, num_workers=4)\n",
    "probs = predict(model, test_loader)\n",
    "\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPpWGH2BqTID"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submit = pd.read_csv(\"gdrive/MyDrive/Simpsons_kaggle/sample_submission.csv\")\n",
    "sample_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yw0zZ-Hdd89s"
   },
   "outputs": [],
   "source": [
    "my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "print(my_submit.shape)\n",
    "my_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIYaqa20iYTL"
   },
   "outputs": [],
   "source": [
    "# TODO : сделайте сабмит (это важно, если Вы не справляетесь, но дошли до этой ячейки, то сообщите в чат и Вам помогут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yonsu2HU5y0H"
   },
   "outputs": [],
   "source": [
    "path = 'gdrive/MyDrive/Simpsons_kaggle/'\n",
    "my_submit.to_csv(path + f\"{model_name}_{feature_extr_epochs}FeatureExtrEpochs-{finetuning_epochs}FinetuningEpochs-submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3M9SQZ7MuUq"
   },
   "source": [
    "## Приключение?\n",
    "\n",
    "А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать. \n",
    "\n",
    "Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову: \n",
    "\n",
    "\n",
    "*   Учим дольше и изменяем гиперпараметры сети\n",
    "*  learning rate, batch size, нормализация картинки и вот это всё\n",
    "*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n",
    "*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n",
    "\n",
    "* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n",
    "\n",
    "* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\n",
    "\n",
    "* Стоит подумать об ансамблях\n",
    "\n",
    "\n",
    "Надеюсь, что у Вас получится!\n",
    "\n",
    "![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "simpsons_efficientnet-b2.ipynb\"",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
